---
title: "Pythagorean_regression_2"
author: "Martin Monkman"
date: "January 7, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In my last post, we looked at the relationship between run differential and wins in Major League Baseball, using Bill James' Pythagorean model.

For this post, I will pick up where I left off, and use linear regression--that workhorse of statistics, machine learning, artificial intelligence, econometrics, etc.--to look more deeply at the relationship. 

### function

Let's write a little **R** function for this equation...in that way, we can save some typing later.

```{r}

winexp_fun <- function(RS, RA) {
  RS^2 / (RS^2 + RA^2)
}

```


## The data


First, we'll load the packages we need. Note that [**tidyverse**](https://www.tidyverse.org/) contains multiple packages, including the graphing package **ggplot2** and the data wrangling package **dplyr**. We'll also load [**broom**](https://broom.tidyverse.org/), which facilitates manipulation of the model outputs.

For this analysis, we'll use the Major League Baseball data from 1961 through 2016--a total of 1476 team seasons. To get the data, we'll use the raw version of the Lahman database (found [here](http://www.seanlahman.com/baseball-archive/statistics/)) take us through the 2017 season, and append a CSV file I have created that contains the 2018 season data (sourced from [baseball-reference.com](https://www.baseball-reference.com/leagues/MLB/2018.shtml). 

![](Lahman_hex.png)


```{r setup}

#tidyverse
library(tidyverse)
library(broom)

#utilities
library(datapasta)
library(here)

#more baseball data
library(Lahman)



```


The code chunk below accesses the `Teams` table from the Lahman database, and wrangles it a bit, and adds (though the `dplyr::mutate` function) two new variables: the team's winning percentage, and using the `winexp_fun` function we wrote above, the win expectation.

```{r}

Teams <- read_csv(here("data", "Teams.csv"))

Teams_sel <- Teams %>%
  filter(yearID >= 1961) %>%
  rename(RS = R) 



```


To copy the data from baseball-reference.com, I used the package [`datapasta`](https://github.com/MilesMcBain/datapasta)

Source: https://www.baseball-reference.com/leagues/MLB/2018.shtml

Tm,#Bat,BatAge,R/G,G,PA,AB,R,H,2B,3B,HR,RBI,SB,CS,BB,SO,BA,OBP,SLG,OPS,OPS+,TB,GDP,HBP,SH,SF,IBB,LOB
ARI,49,29.2,4.28,162,6157,5460,693,1283,259,50,176,658,79,25,560,1460,.235,.310,.397,.707,84,2170,110,52,38,45,36,1086
ATL,58,27.3,4.69,162,6266,5582,759,1433,314,29,175,717,90,36,511,1290,.257,.324,.417,.742,99,2330,99,66,49,43,53,1143
BAL,56,28.4,3.84,162,6034,5507,622,1317,242,15,188,593,81,22,422,1412,.239,.298,.391,.689,91,2153,132,57,13,35,19,1027
BOS,44,27.7,5.41,162,6302,5623,876,1509,355,31,208,829,125,31,569,1253,.268,.339,.453,.792,112,2550,130,55,7,48,38,1124
CHC,50,27.2,4.67,163,6369,5624,761,1453,286,34,167,722,66,38,576,1388,.258,.333,.410,.744,95,2308,107,78,40,46,67,1224
CHW,51,26.5,4.05,162,6071,5523,656,1332,259,40,182,639,98,41,425,1594,.241,.302,.401,.703,93,2217,99,66,24,32,18,1050
CIN,53,27.2,4.30,162,6240,5532,696,1404,251,25,172,665,77,33,559,1376,.254,.328,.401,.729,94,2221,128,65,49,35,35,1179
CLE,49,29.4,5.05,162,6300,5595,818,1447,297,19,216,786,135,36,554,1189,.259,.332,.434,.766,105,2430,98,80,25,44,32,1147
COL,41,28.7,4.79,163,6178,5541,780,1418,280,42,210,748,95,33,507,1397,.256,.322,.435,.757,90,2412,114,51,42,37,38,1067
DET,49,27.9,3.89,162,6029,5494,630,1326,284,35,135,597,70,30,428,1341,.241,.300,.380,.680,85,2085,110,52,15,40,18,1071
HOU,41,28.2,4.92,162,6146,5453,797,1390,278,18,205,763,71,26,565,1197,.255,.329,.425,.754,109,2319,156,61,14,45,19,1052
KCR,49,28.6,3.94,162,6063,5505,638,1350,283,29,155,606,117,38,427,1310,.245,.305,.392,.697,91,2156,123,67,24,40,13,1063
LAA,60,29.6,4.45,162,6108,5472,721,1323,249,23,214,690,89,22,514,1300,.242,.313,.413,.726,100,2260,111,73,7,39,38,1071
LAD,52,28.1,4.93,163,6358,5572,804,1394,296,33,235,756,75,24,647,1436,.250,.333,.442,.774,109,2461,119,61,39,39,47,1163
MIA,51,27.5,3.66,161,6083,5488,589,1303,222,24,128,554,45,31,455,1384,.237,.303,.357,.659,87,1957,119,73,32,31,26,1123
MIL,53,28.8,4.63,163,6210,5542,754,1398,252,24,218,711,124,32,537,1458,.252,.323,.424,.747,99,2352,128,58,29,41,32,1106
MIN,54,28.2,4.56,162,6154,5526,738,1380,318,22,166,704,47,27,534,1328,.250,.318,.405,.723,95,2240,89,37,19,38,25,1087
NYM,56,28.3,4.17,162,6177,5468,676,1282,265,34,170,649,71,39,566,1404,.234,.312,.389,.701,97,2125,116,73,28,42,36,1104
NYY,49,27.2,5.25,162,6271,5515,851,1374,269,23,267,821,63,21,625,1421,.249,.329,.451,.781,108,2490,107,62,10,59,21,1100
OAK,53,28.0,5.02,162,6255,5579,813,1407,322,20,227,778,35,21,550,1381,.252,.325,.439,.764,109,2450,136,76,6,44,18,1085
PHI,48,26.7,4.18,162,6136,5424,677,1271,241,30,186,653,69,26,582,1520,.234,.314,.393,.707,89,2130,102,64,32,32,33,1120
PIT,48,27.8,4.30,161,6066,5447,692,1381,290,38,157,665,70,38,474,1229,.254,.317,.407,.725,98,2218,121,59,31,52,38,1071
SDP,49,26.8,3.81,162,6059,5486,617,1289,250,30,162,583,95,36,471,1523,.235,.297,.380,.677,87,2085,122,31,35,36,28,1028
SEA,53,29.8,4.18,162,6087,5513,677,1402,256,32,176,644,79,37,430,1221,.254,.314,.408,.722,102,2250,128,70,29,41,17,1084
SFG,48,29.8,3.72,162,6113,5541,603,1324,255,30,133,573,77,34,448,1467,.239,.300,.368,.667,84,2038,113,49,33,42,40,1101
STL,49,28.0,4.69,162,6200,5498,759,1369,248,9,205,725,63,32,525,1380,.249,.321,.409,.730,99,2250,92,80,46,48,40,1101
TBR,54,27.1,4.42,162,6195,5475,716,1415,274,43,150,664,128,51,540,1388,.258,.333,.406,.740,105,2225,122,101,28,50,17,1156
TEX,50,27.4,4.55,162,6163,5453,737,1308,266,24,194,696,74,35,555,1484,.240,.318,.404,.722,88,2204,104,88,33,34,16,1093
TOR,63,28.9,4.38,162,6076,5477,709,1336,320,16,217,680,47,30,499,1387,.244,.312,.427,.739,103,2339,118,58,5,37,15,1036
WSN,53,27.6,4.76,162,6288,5517,771,1402,284,25,191,737,119,33,631,1289,.254,.335,.419,.753,98,2309,104,59,41,40,56,1180


```{r}

Teams_hit_2018 <- read_csv(here("data", "Teams_hit_2018.txt"))

Teams_pit_2018 <- read_csv(here("data", "Teams_pit_2018.txt"))

ls.str(Teams_hit_2018)

```



add winning percentage and win expectancy

```{r}
Teams_sel %>%
  mutate(winpct = W / G, 
         winexp = winexp_fun(RS, RA))

```



basic plot

```{r}

we_scatterplot <- ggplot(data = Teams_sel, aes(x = winexp, y = winpct)) +
  geom_blank() +
  coord_fixed() +
  scale_x_continuous(breaks = seq(0.2, 0.8, by = 0.1),
                     limits = c(0.2, 0.8)) +
  scale_y_continuous(breaks = seq(0.2, 0.8, by = 0.1),
                     limits = c(0.2, 0.8)) 

we_scatterplot

```



#### The regression model

Let's model the relationship between the win expectation `winexp` and winning percentage `winpct`. **R** makes regression model building easy; the `lm()` function in base **R**  is all that it takes to run a linear regression, that workhorse of statistics, machine learning, artificial intelligence, econometrics, ... 

Sidebar: If you're not familiar with linear regression as a statistical method and/or how to run and interpret linear regression in R, there's an abundance of resources now available. One such is chapter 15 of Danielle Navarro's book [_Learning Statistics With R_](https://learningstatisticswithr-bookdown.netlify.com/regression.html), which gets a nod for 

* being an open on-line text, 

* relies on RStudio as the interface, and 

* is not without a touch of levity.

With a model object assigned by the `lm()` function, we can use the `print()` and `summary()` functions let us see the key elements from the model.


```{r}

winexp_mod <- lm(winexp ~ winpct, Teams_sel)

print(winexp_mod)

summary(winexp_mod)

```



R also makes it very easy to add the regression model line to the scatter plot, with the `geom_smooth()` function. Note that we have to specify the `method = lm`; the default is a [LOESS smoothing](https://en.wikipedia.org/wiki/Local_regression) curve.


```{r}

we_scatterplot +
  geom_point() +
  geom_smooth(method = lm)


```



We can use the **broom** package to get the model statistics.

```{r}

broom::tidy(winexp_mod)

```


```{r}

glance(winexp_mod)

```

```{r}

winexp_mod_tidy <- augment(winexp_mod)
head(winexp_mod_tidy)

```



The Pythagorean model explains a lot of the variation: the R-squared value of `r glance(winexp_mod)$r.squared`.



And just for fun, let's add a visual comparison of the "unity" line shown in red (where `winexp` == `winpct`) and the line of best fit created by the regression model (in blue). There's a slight discrepancy; it makes intuitive sense that teams with big run differentials are winning more games by bigger margins than average, and are "underperforming" relative to the Pythagorean prediction. Conversely, teams at the bottom left are overperforming Pythagorean, suggesting winning more close games. The warrants further analysis, but is a project for another day.

If we omit the `geom_point()` layer, all that gets shown are the lines. I have simply commented out that line, and added the `geom_smooth()` (as was done above).

```{r}

we_scatterplot +
#  geom_point() +
  geom_segment(aes(x = 0.25, xend = 0.75, y = 0.25, yend = 0.75), colour = "red", size = 1.5) +
  geom_smooth(method = lm, size = 1.5)

```




```{r}

final_we_scatterplot <-
we_scatterplot +
  geom_point(colour = "grey75") +
  geom_segment(aes(x = 0.25, xend = 0.75, y = 0.25, yend = 0.75), colour = "red", size = 1.5) +
  geom_smooth(method = lm, size = 1.5)

final_we_scatterplot

```



---


## ETC - future analysis possibilities

Idea: filter where .se.fit is poor (i.e. big residual), plot -- see where the 2018 Mariners sit on the list


Idea: regression to the mean over the course of a season, via a Bayesian MCMC approach 



---

#### R pacakge references

**broom** 

* David Robinson, 2015-03-19, ["broom: a package for tidying statistical models into data frames"](https://www.r-bloggers.com/broom-a-package-for-tidying-statistical-models-into-data-frames/)

* [Introduction to broom](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)

* also https://cran.r-project.org/web/packages/broom/vignettes/broom.html 

* [broom 0.5.0](https://www.tidyverse.org/articles/2018/07/broom-0-5-0/) 



#### `ggplot2 3.0.0`

This also seemed like a good time to take [the latest version of `ggplot2` (3.0.0)](https://www.tidyverse.org/articles/2018/07/ggplot2-3-0-0/) for a test run.



#### `ggeffects` package

Daniel Lüdecke, 2018-07-04, ["Marginal Effects for Regression Models in R"](https://www.r-bloggers.com/marginal-effects-for-regression-models-in-r-rstats-dataviz/)



-30-
